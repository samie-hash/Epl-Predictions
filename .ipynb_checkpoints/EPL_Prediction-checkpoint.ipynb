{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/distributed/utils.py:139: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [Errno 101] Network is unreachable\n",
      "  RuntimeWarning,\n"
     ]
    }
   ],
   "source": [
    "# necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# data\n",
    "s2019_2020 = pd.read_csv('data/2019-2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HTHG', \n",
    "           'HTAG', 'HS', 'AS', 'HST', 'AST', 'HC', 'AC']\n",
    "s2019_2020 = s2019_2020[columns]\n",
    "s2019_2020.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form(data, k=0.33):\n",
    "    clubs = data.HomeTeam.unique()\n",
    "    form_dict = {}\n",
    "    for club in clubs:\n",
    "        form_dict[club] = [1.0]\n",
    "        \n",
    "    for idx, row in data.iterrows():\n",
    "        ht_current_form = form_dict[row['HomeTeam']][-1]\n",
    "        at_current_form = form_dict[row['AwayTeam']][-1]\n",
    "\n",
    "        if row['FTR'] == 'H':\n",
    "            form_dict[row['HomeTeam']].append(ht_current_form + (k * at_current_form))\n",
    "            form_dict[row['AwayTeam']].append(at_current_form - (k * at_current_form))\n",
    "    \n",
    "        if row['FTR'] == 'A':\n",
    "            form_dict[row['AwayTeam']].append(at_current_form + (k * ht_current_form))\n",
    "            form_dict[row['HomeTeam']].append(ht_current_form - (k * ht_current_form))\n",
    "            \n",
    "        if row['FTR'] == 'D':\n",
    "            form_dict[row['HomeTeam']].append(ht_current_form - (k * (ht_current_form - at_current_form)))\n",
    "            form_dict[row['AwayTeam']].append(at_current_form - (k * (at_current_form - ht_current_form)))\n",
    "            \n",
    "    return form_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_form(data):\n",
    "    data['HF'] = 0.0\n",
    "    data['AF'] = 0.0\n",
    "\n",
    "    form_data = form(data)\n",
    "\n",
    "    for club in data.HomeTeam.unique(): \n",
    "        mask = (data['HomeTeam'] == club) | (data['AwayTeam'] == club)\n",
    "        k = 0\n",
    "\n",
    "        for idx, row in data[mask].iterrows():\n",
    "            if row['HomeTeam'] == club:\n",
    "                data.loc[idx, 'HF'] = form_data[club][k]\n",
    "            if row['AwayTeam'] == club:\n",
    "                data.loc[idx, 'AF'] = form_data[club][k]\n",
    "            k += 1\n",
    "    return data\n",
    "\n",
    "s2019_2020 = transform_form(s2019_2020)\n",
    "s2019_2020.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_ftr(row, column_name):\n",
    "    if row[column_name] == 'H':\n",
    "        return 1\n",
    "    if row[column_name] == 'A':\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2019_2020.FTR = s2019_2020.apply(lambda row: transform_ftr(row, 'FTR'), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_statistics(X, avg_HS, avg_AS, avg_AC, avg_HC):\n",
    "    team_statistics = pd.DataFrame(columns=['Club Name', 'HTG', 'ATG', 'HTC', 'ATC', 'HAS', 'AAS']) \n",
    "    home_team_group = X.groupby('HomeTeam')\n",
    "    away_team_group = X.groupby('AwayTeam')\n",
    "    num_games = X.shape[0] / 20\n",
    "\n",
    "    team_statistics['Club Name'] = home_team_group.groups.keys()\n",
    "    team_statistics['HTG'] = home_team_group.FTHG.sum().values\n",
    "    team_statistics['ATG'] = away_team_group.FTAG.sum().values\n",
    "    team_statistics['HTC'] = home_team_group.FTAG.sum().values\n",
    "    team_statistics['ATC'] = away_team_group.FTHG.sum().values\n",
    "\n",
    "    team_statistics['HAS'] = (team_statistics['HTG'] / num_games) / avg_HS\n",
    "    team_statistics['AAS'] = (team_statistics['ATG'] / num_games) / avg_AS\n",
    "    team_statistics['HDS'] = (team_statistics['ATC'] / num_games) / avg_AC\n",
    "    team_statistics['ADS'] = (team_statistics['HTC'] / num_games) / avg_HC\n",
    "\n",
    "    return team_statistics\n",
    "\n",
    "def transform_stat(data):\n",
    "    data['HAS'] = 0.0\n",
    "    data['AAS'] = 0.0\n",
    "    data['HDS'] = 0.0\n",
    "    data['ADS'] = 0.0\n",
    "    data['HXG'] = 0.0\n",
    "    data['AXG'] = 0.0\n",
    "\n",
    "    HAS = []\n",
    "    AAS = []\n",
    "    HDS = []\n",
    "    ADS = []\n",
    "    HXG = []\n",
    "    AXG = []\n",
    "\n",
    "    avg_HS = data.FTHG.sum() / data.shape[0]\n",
    "    avg_AS = data.FTAG.sum() / data.shape[0]\n",
    "    avg_HC = avg_AS\n",
    "    avg_AC = avg_HS\n",
    "\n",
    "    team_stat = get_team_statistics(data, avg_HS, avg_AS, avg_AC, avg_HC)\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        HAS.append(team_stat[team_stat['Club Name'] == row['HomeTeam']]['HAS'].values[0])\n",
    "        AAS.append(team_stat[team_stat['Club Name'] == row['AwayTeam']]['AAS'].values[0])\n",
    "        HDS.append(team_stat[team_stat['Club Name'] == row['HomeTeam']]['HDS'].values[0])\n",
    "        ADS.append(team_stat[team_stat['Club Name'] == row['AwayTeam']]['ADS'].values[0])\n",
    "\n",
    "    data['HAS'] = HAS\n",
    "    data['AAS'] = AAS\n",
    "    data['HDS'] = HDS\n",
    "    data['ADS'] = ADS\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        HXG.append(row['HAS'] * row['ADS'] * avg_HS)\n",
    "        AXG.append(row['AAS'] * row['HDS'] * avg_AS)\n",
    "\n",
    "    data['HXG'] = HXG\n",
    "    data['AXG'] = AXG\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2019_2020 = transform_stat(s2019_2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recent K Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_perf(data, k=3):\n",
    "    data['PastFTHG'] = 0.0\n",
    "    for idx in range(data.shape[0]-1, -1, -1):\n",
    "        row = data.loc[idx]\n",
    "        ht = row.HomeTeam\n",
    "        at = row.AwayTeam\n",
    "\n",
    "        ht_stats = data[idx:][(data.HomeTeam == ht)|(data.AwayTeam == ht)].head(k)\n",
    "        at_stats = data[idx:][(data.HomeTeam == at)|(data.AwayTeam == at)].head(k)\n",
    "\n",
    "        data.loc[idx, 'PastFTHG'] = ht_stats[ht_stats['HomeTeam'] == ht].FTHG.sum() + ht_stats[ht_stats['AwayTeam'] == ht].FTAG.sum()\n",
    "        data.loc[idx, 'PastFTAG'] = at_stats[at_stats['HomeTeam'] == at].FTHG.sum() + at_stats[at_stats['AwayTeam'] == at].FTAG.sum()\n",
    "        data.loc[idx, 'PastHST'] = ht_stats[ht_stats['HomeTeam'] == ht].HST.sum() + ht_stats[ht_stats['AwayTeam'] == ht].AST.sum()\n",
    "        data.loc[idx, 'PastAST'] = at_stats[at_stats['HomeTeam'] == at].HST.sum() + ht_stats[ht_stats['AwayTeam'] == ht].AST.sum()\n",
    "        data.loc[idx, 'PastHS'] = ht_stats[ht_stats['HomeTeam'] == ht].HS.sum() + ht_stats[ht_stats['AwayTeam'] == ht].AS.sum()\n",
    "        data.loc[idx, 'PastAS'] = at_stats[at_stats['HomeTeam'] == at].HS.sum() + ht_stats[ht_stats['AwayTeam'] == ht].AS.sum()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2019_2020 = k_perf(s2019_2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = s2019_2020[['HAS', 'AAS', 'HDS', 'ADS', 'HXG', 'AXG', 'PastFTHG', 'PastFTAG', 'PastHST',\n",
    "               'PastAST', 'PastHS', 'PastAS']]\n",
    "y = s2019_2020['FTR']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=34, stratify=s2019_2020.FTR)\n",
    "\n",
    "print('X_train.shape: {}'.format(X_train.shape))\n",
    "print('X_test.shape: {}'.format(X_test.shape))\n",
    "print('y_train.shape: {}'.format(y_train.shape))\n",
    "print('y_test.shape: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize models\n",
    "knn = KNeighborsClassifier(n_neighbors=10).fit(X_train, y_train)\n",
    "rf = RandomForestClassifier(n_estimators=1000).fit(X_train, y_train)\n",
    "xgb = XGBClassifier(n_estimators=1000).fit(X_train, y_train)\n",
    "tr = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "gnb = GaussianNB().fit(X_train, y_train)\n",
    "svc = SVC(C=10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KNN:\\n  train score: {:.3f}, test score: {:.3f}'.format(knn.score(X_train, y_train), knn.score(X_test, y_test)))\n",
    "print('RF:\\n  train score: {:.3f}, test score: {:.3f}'.format(rf.score(X_train, y_train), rf.score(X_test, y_test)))\n",
    "print('XGB:\\n  train score: {:.3f}, test score: {:.3f}'.format(xgb.score(X_train, y_train), xgb.score(X_test, y_test)))\n",
    "print('TR:\\n  train score: {:.3f}, test score: {:.3f}'.format(tr.score(X_train, y_train), tr.score(X_test, y_test)))\n",
    "print('GNB:\\n  train score: {:.3f}, test score: {:.3f}'.format(gnb.score(X_train, y_train), gnb.score(X_test, y_test)))\n",
    "print('SVC:\\n  train score: {:.3f}, test score: {:.3f}'.format(svc.score(X_train, y_train), svc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_diff_features(data):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    scaled = scaler.fit_transform(data.drop(['HomeTeam', 'AwayTeam', 'FTR'], axis=1))\n",
    "    columns = set(data.columns) - {'HomeTeam', 'AwayTeam', 'FTR'}\n",
    "    data[list(columns)] = scaled\n",
    "    \n",
    "    data['AttackDiff'] = data['HAS'] - data['AAS']\n",
    "    data['DefenceDiff'] = data['HDS'] - data['ADS']\n",
    "    data['ExpGoalDiff'] = data['HXG'] - data['AXG']\n",
    "    data['PastGoalDiff'] = data['PastFTHG'] - data['PastFTAG']\n",
    "    data['PastShotsOnTargetDiff'] = data['PastHST'] - data['PastAST']\n",
    "    data['PastShotsDiff'] = data['PastHS'] - data['PastAS']\n",
    "    data['AttackDiff'] = scaler.fit_transform(data['AttackDiff'].values.reshape(-1, 1))\n",
    "    data['DefenceDiff'] = scaler.fit_transform(data['DefenceDiff'].values.reshape(-1, 1))\n",
    "    data['ExpGoalDiff'] = scaler.fit_transform(data['ExpGoalDiff'].values.reshape(-1, 1))\n",
    "    data['PastGoalDiff'] = scaler.fit_transform(data['PastGoalDiff'].values.reshape(-1, 1))\n",
    "    data['PastShotsOnTargetDiff'] = scaler.fit_transform(data['PastShotsOnTargetDiff'].values.reshape(-1, 1))\n",
    "    data['PastShotsDiff'] = scaler.fit_transform(data['PastShotsDiff'].values.reshape(-1, 1))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2019_2020 = add_diff_features(s2019_2020)\n",
    "s2019_2020.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = s2019_2020[['AttackDiff', 'DefenceDiff', 'ExpGoalDiff', 'PastGoalDiff', 'PastShotsOnTargetDiff',\n",
    "                'PastShotsDiff']]\n",
    "y2 = s2019_2020['FTR']\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.15, random_state=34, stratify=s2019_2020.FTR)\n",
    "\n",
    "print('X_train.shape: {}'.format(X2_train.shape))\n",
    "print('X_test.shape: {}'.format(X2_test.shape))\n",
    "print('y_train.shape: {}'.format(y2_train.shape))\n",
    "print('y_test.shape: {}'.format(y2_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize models\n",
    "knn = KNeighborsClassifier(n_neighbors=10).fit(X2_train, y2_train)\n",
    "rf = RandomForestClassifier(n_estimators=1000).fit(X2_train, y2_train)\n",
    "xgb = XGBClassifier(n_estimators=1000).fit(X2_train, y2_train)\n",
    "tr = DecisionTreeClassifier().fit(X2_train, y2_train)\n",
    "gnb = GaussianNB().fit(X2_train, y2_train)\n",
    "svc = SVC(C=10).fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KNN:\\n  train score: {:.3f}, test score: {:.3f}'.format(knn.score(X2_train, y2_train), knn.score(X2_test, y2_test)))\n",
    "print('RF:\\n  train score: {:.3f}, test score: {:.3f}'.format(rf.score(X2_train, y2_train), rf.score(X2_test, y2_test)))\n",
    "print('XGB:\\n  train score: {:.3f}, test score: {:.3f}'.format(xgb.score(X2_train, y2_train), xgb.score(X2_test, y2_test)))\n",
    "print('TR:\\n  train score: {:.3f}, test score: {:.3f}'.format(tr.score(X2_train, y2_train), tr.score(X2_test, y2_test)))\n",
    "print('GNB:\\n  train score: {:.3f}, test score: {:.3f}'.format(gnb.score(X2_train, y2_train), gnb.score(X2_test, y2_test)))\n",
    "print('SVC:\\n  train score: {:.3f}, test score: {:.3f}'.format(svc.score(X2_train, y2_train), svc.score(X2_test, y2_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_scores = cross_val_score(rf, X2, y2, cv=10)\n",
    "tree_scores = cross_val_score(tr, X2, y2, cv=10)\n",
    "knn_scores = cross_val_score(knn, X2, y2, cv=10)\n",
    "xgb_scores = cross_val_score(xgb, X2, y2, cv=10)\n",
    "gnb_scores = cross_val_score(gnb, X2, y2, cv=10)\n",
    "svc_scores = cross_val_score(svc, X2, y2, cv=10)\n",
    "print('Random Forest Classifier Accuracy: {:.2f}%'.format(forest_scores.mean() * 100))\n",
    "print('Tree Classifier Accuracy: {:.2f}%'.format(tree_scores.mean() * 100))\n",
    "print('K-Nearest Neighbor Accuracy: {:.2f}%'.format(knn_scores.mean() * 100))\n",
    "print('XGB Classifier Accuracy: {:.2f}%'.format(xgb_scores.mean() * 100))\n",
    "print('Gaussian Naive Bayes Classifier Accuracy: {:.2f}%'.format(gnb_scores.mean() * 100))\n",
    "print('Support Vector Classifier Accuracy: {:.2f}%'.format(svc_scores.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=.15)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=.15)\n",
    "gnb.fit(X_train, y_train)\n",
    "predictions = gnb.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2018_2019 = pd.read_csv('data/2018-2019.csv')\n",
    "s2017_2018 = pd.read_csv('data/2017-2018.csv')\n",
    "s2016_2017 = pd.read_csv('data/2016-2017.csv')\n",
    "s2015_2016 = pd.read_csv('data/2015-2016.csv')\n",
    "s2014_2015 = pd.read_csv('data/2014-2015.csv')\n",
    "columns = ['HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HTHG', \n",
    "           'HTAG', 'HS', 'AS', 'HST', 'AST', 'HC', 'AC']\n",
    "s2018_2019 = s2018_2019[columns]\n",
    "s2017_2018 = s2017_2018[columns]\n",
    "s2016_2017 = s2016_2017[columns]\n",
    "s2015_2016 = s2015_2016[columns]\n",
    "s2014_2015 = s2014_2015[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2018_2019.FTR = s2018_2019.apply(lambda row: transform_ftr(row, 'FTR'), axis=1)\n",
    "s2017_2018.FTR = s2017_2018.apply(lambda row: transform_ftr(row, 'FTR'), axis=1)\n",
    "s2016_2017.FTR = s2016_2017.apply(lambda row: transform_ftr(row, 'FTR'), axis=1)\n",
    "s2015_2016.FTR = s2015_2016.apply(lambda row: transform_ftr(row, 'FTR'), axis=1)\n",
    "s2014_2015.FTR = s2014_2015.apply(lambda row: transform_ftr(row, 'FTR'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2018_2019 = transform_stat(s2018_2019)\n",
    "s2017_2018 = transform_stat(s2017_2018)\n",
    "s2016_2017 = transform_stat(s2016_2017)\n",
    "s2015_2016 = transform_stat(s2015_2016)\n",
    "s2014_2015 = transform_stat(s2014_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2014_2015 = k_perf(s2014_2015)\n",
    "s2015_2016 = k_perf(s2015_2016)\n",
    "s2016_2017 = k_perf(s2016_2017)\n",
    "s2017_2018 = k_perf(s2017_2018)\n",
    "s2018_2019 = k_perf(s2018_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2014_2015 = add_diff_features(s2014_2015)\n",
    "s2015_2016 = add_diff_features(s2015_2016)\n",
    "s2016_2017 = add_diff_features(s2016_2017)\n",
    "s2017_2018 = add_diff_features(s2017_2018)\n",
    "s2018_2019 = add_diff_features(s2018_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2019_2020 = s2019_2020.append(s2018_2019, sort=False, ignore_index=True)\n",
    "s2019_2020 = s2019_2020.append(s2017_2018, sort=False, ignore_index=True)\n",
    "s2019_2020 = s2019_2020.append(s2016_2017, sort=False, ignore_index=True)\n",
    "s2019_2020 = s2019_2020.append(s2015_2016, sort=False, ignore_index=True)\n",
    "s2019_2020 = s2019_2020.append(s2014_2015, sort=False, ignore_index=True)\n",
    "s2019_2020.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = s2019_2020[['AttackDiff', 'DefenceDiff', 'ExpGoalDiff', 'PastGoalDiff', 'PastShotsOnTargetDiff',\n",
    "                'PastShotsDiff']]\n",
    "y2 = s2019_2020['FTR']\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.15, random_state=34, stratify=s2019_2020.FTR)\n",
    "\n",
    "print('X_train.shape: {}'.format(X2_train.shape))\n",
    "print('X_test.shape: {}'.format(X2_test.shape))\n",
    "print('y_train.shape: {}'.format(y2_train.shape))\n",
    "print('y_test.shape: {}'.format(y2_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize models\n",
    "knn = KNeighborsClassifier(n_neighbors=10).fit(X2_train, y2_train)\n",
    "rf = RandomForestClassifier(n_estimators=1000).fit(X2_train, y2_train)\n",
    "xgb = XGBClassifier(n_estimators=1000).fit(X2_train, y2_train)\n",
    "tr = DecisionTreeClassifier().fit(X2_train, y2_train)\n",
    "gnb = GaussianNB().fit(X2_train, y2_train)\n",
    "svc = SVC(C=10).fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KNN:\\n  train score: {:.3f}, test score: {:.3f}'.format(knn.score(X2_train, y2_train), knn.score(X2_test, y2_test)))\n",
    "print('RF:\\n  train score: {:.3f}, test score: {:.3f}'.format(rf.score(X2_train, y2_train), rf.score(X2_test, y2_test)))\n",
    "print('XGB:\\n  train score: {:.3f}, test score: {:.3f}'.format(xgb.score(X2_train, y2_train), xgb.score(X2_test, y2_test)))\n",
    "print('TR:\\n  train score: {:.3f}, test score: {:.3f}'.format(tr.score(X2_train, y2_train), tr.score(X2_test, y2_test)))\n",
    "print('GNB:\\n  train score: {:.3f}, test score: {:.3f}'.format(gnb.score(X2_train, y2_train), gnb.score(X2_test, y2_test)))\n",
    "print('SVC:\\n  train score: {:.3f}, test score: {:.3f}'.format(svc.score(X2_train, y2_train), svc.score(X2_test, y2_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_scores = cross_val_score(rf, X2, y2, cv=10)\n",
    "tree_scores = cross_val_score(tr, X2, y2, cv=10)\n",
    "knn_scores = cross_val_score(knn, X2, y2, cv=10)\n",
    "xgb_scores = cross_val_score(xgb, X2, y2, cv=10)\n",
    "gnb_scores = cross_val_score(gnb, X2, y2, cv=10)\n",
    "svc_scores = cross_val_score(svc, X2, y2, cv=10)\n",
    "print('Random Forest Classifier Accuracy: {:.2f}%'.format(forest_scores.mean() * 100))\n",
    "print('Tree Classifier Accuracy: {:.2f}%'.format(tree_scores.mean() * 100))\n",
    "print('K-Nearest Neighbor Accuracy: {:.2f}%'.format(knn_scores.mean() * 100))\n",
    "print('XGB Classifier Accuracy: {:.2f}%'.format(xgb_scores.mean() * 100))\n",
    "print('Gaussian Naive Bayes Classifier Accuracy: {:.2f}%'.format(gnb_scores.mean() * 100))\n",
    "print('Support Vector Classifier Accuracy: {:.2f}%'.format(svc_scores.mean() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 20, 50, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001, 0.0001, 0.00001],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "clf = GridSearchCV(svc, param_grid, cv=10, n_jobs=-1)\n",
    "clf.fit(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(**clf.best_params_)\n",
    "svc.fit(X2_train, y2_train)\n",
    "print('X_test score: {}'.format(svc.score(X2_test, y2_test)))\n",
    "predictions = svc.predict(X2_test)\n",
    "print(classification_report(y2_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knn Hyperpameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': list(range(1, 200)),\n",
    "    'leaf_size': list(range(1, 50)),\n",
    "    'p': [1, 2]\n",
    "}\n",
    "clf = GridSearchCV(knn, param_grid, cv=10, n_jobs=-1)\n",
    "clf.fit(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(**clf.best_params_)\n",
    "knn.fit(X2_train, y2_train)\n",
    "print('X_test score: {}'.format(knn.score(X2_test, y2_test)))\n",
    "predictions = knn.predict(X2_test)\n",
    "print(classification_report(y2_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X2_train, y2_train)\n",
    "print('X_test score: {}'.format(gnb.score(X2_test, y2_test)))\n",
    "predictions = gnb.predict(X2_test)\n",
    "print(classification_report(y2_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeAttributes(BaseEstimator):\n",
    "    \"\"\"\n",
    "        Engineer new attributes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = transform_stat(X)\n",
    "        X = k_perf(X)\n",
    "        X = add_diff_features(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2014_2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2019_2020.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(C=10, gamma=0.01, kernel='rbf')\n",
    "model.fit(X2_train, y2_train)\n",
    "print('Train score: {}'.format(model.score(X2_train, y2_train)))\n",
    "print('Test score: {}'.format(model.score(X2_test, y2_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('model2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_back_ftr(row, column_name):\n",
    "    if row[column_name] == 1:\n",
    "        return 'H'\n",
    "    if row[column_name] == -1:\n",
    "        return 'A'\n",
    "    else:\n",
    "        return 'D'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = Pipeline(steps=[('Make Attributes', MakeAttributes())])\n",
    "\n",
    "model = pickle.load(open('model2.pkl', 'rb'))\n",
    "\n",
    "data = pd.read_csv('data/2020-2021.csv')\n",
    "data = data[columns]\n",
    "predict_columns = []\n",
    "data_tr = model_pipeline.fit_transform(data)[['AttackDiff', 'DefenceDiff', 'ExpGoalDiff', 'PastGoalDiff', 'PastShotsOnTargetDiff',\n",
    "                'PastShotsDiff']]\n",
    "predictions = model.predict(data_tr)\n",
    "data = data[['HomeTeam', 'AwayTeam', 'FTR']]\n",
    "data['Predictions'] = predictions\n",
    "data.Predictions = data.apply(lambda row: transform_back_ftr(row, 'Predictions'), axis=1)\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
